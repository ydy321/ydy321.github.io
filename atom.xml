<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>YDY321</title>
  
  <subtitle>道阻且长，行则将至；行而不辍，未来可期</subtitle>
  <link href="https://github.com/ydy321/ydy321.git/atom.xml" rel="self"/>
  
  <link href="https://github.com/ydy321/ydy321.git/"/>
  <updated>2023-10-20T14:20:24.555Z</updated>
  <id>https://github.com/ydy321/ydy321.git/</id>
  
  <author>
    <name>ydy321</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="https://github.com/ydy321/ydy321.git/2023/10/21/Contour%20Context%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <id>https://github.com/ydy321/ydy321.git/2023/10/21/Contour%20Context%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</id>
    <published>2023-10-21T03:29:09.476Z</published>
    <updated>2023-10-20T14:20:24.555Z</updated>
    
    <content type="html"><![CDATA[<h5 id="Contour-Context-Abstract-Structural-Distribution-for-3D-LiDAR-Loop-Detection-and-Metric-Pose-Estimation-论文阅读-ICRA’23"><a href="#Contour-Context-Abstract-Structural-Distribution-for-3D-LiDAR-Loop-Detection-and-Metric-Pose-Estimation-论文阅读-ICRA’23" class="headerlink" title="Contour Context: Abstract Structural Distribution for 3D LiDAR Loop Detection and Metric Pose Estimation 论文阅读  ICRA’23"></a>Contour Context: Abstract Structural Distribution for 3D LiDAR Loop Detection and Metric Pose Estimation 论文阅读  ICRA’23</h5><p><strong>Authors:</strong> Binqian Jiang and Shaojie Shen from the <a href="https://uav.hkust.edu.hk/">HKUST Aerial Robotics Group</a>.</p><h6 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h6><p>本文针对城市自动驾驶场景，提出了一种简单、有效、高效的具有精确3自由度度量姿态估计的拓扑闭环检测方案Contour Context。</p><p>我们将三维激光雷达点投影的直角鸟瞰图(BEV)解释为结构的分层分布。</p><p>为了恢复bev的高程信息，我们将其在不同的高度切片，并将每一层的连通像素构成轮廓。每个轮廓都由抽象信息参数化，如像素数、中心位置、协方差和平均高度。依次采用离散和连续两种方法计算两个BEV的相似度。</p><p>第一步考虑由特定地点的轮廓形成的类图星座的几何一致性。</p><p>第二步将大部分轮廓线建模为2.5D高斯混合模型，用于计算连续空间的相关和优化相对变换。检索键的设计是为了加速对分层kd -树索引的数据库的搜索。我们通过与最近在公共数据集上的工作进行比较来验证我们的方法的有效性。</p><h6 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h6><p>为了实现强大和长期的自主导航，感知的一个基本任务是识别以前访问过的地方。这个任务在许多实际和关键的机器人应用中都可以找到，例如，在有先验地图情况下启动，从定位失败中恢复，以及同步定位和映射(SLAM)[1]。<strong>基于视觉的回环检测[2]、[3]的研究较多，但其检测方法常因光照、视点或季节变化而引起视觉特征的变化</strong>。激光探测和测距(LiDAR)传感器通过准确捕获底层结构信息[4]-[8]，对外观变化更具弹性，这表明在全局定位方面有很大的潜力。</p><p>在自动驾驶中，当车辆重新回到曾经过地方时，车辆的相对姿态在横摇、俯仰和垂直方向上变化很小，因此可以假设车辆在重新定位时的姿态是2D的。这种假设促使许多[4]，[9]-[13]使用3D点云的鸟瞰投影(BEV)进行环路检测。然而，<strong>如何有效地生成强调场景不变性的有效地点描述符</strong>仍然是一个有待解决的问题。基于极坐标投影的方法在寻找最佳对齐时通常需要平移描述符，这实质上是暴力搜索[4]，[9]，[12]。此外，它们对相对平移也很敏感。图像特征检测器和描述符依赖于强度(或梯度变化)在小范围内的不变性。</p><p>而在三维激光雷达笛卡尔BEV中，由于激光雷达点的稀疏性和传感器的运动，这种方法是不稳定的。为了缓解这一问题，基于笛卡尔投影的方法往往遵循图像匹配的流程，主要是对图像进行滤波，提取关键点并匹配[10]，[13]。它们<strong>对资源要求很高</strong>，因为需要使用一组滤波器，而且在相对姿态估计中涉及到太多的点。</p><p>为了更好地利用BEV图像进行环路检测，我们提出了轮廓上下文(Cont2)，这是一种简单、有效、高效的拓扑环路回环检测流程，具有精确的3DoF度量姿态估计(MPE)。我们的关键观点是，<strong>用BEV表示的场景可以被建模为显著结构的概率分布。分布比点更稳定和可重复，因为它们通常是一个“平均值”。</strong>这种新的解释利用了激光雷达bev特有的嵌入式结构信息，这在以往的研究中很少涉及。<strong>通过将最高点投影到每个BEV像素上，我们保持了地图的高程。在不同高度对BEV图像进行切片，可以在每一层创建包含2D结构信息的轮廓(即连通像素)。</strong>我们将原始轮廓压缩成一个椭圆和一些其他变量，这是环境组件的紧凑而统一的参数化。采用依次使用离散和连续两种方法计算两种BEV的相似度。</p><p>第一步检查由多个等高线组成的类图星座在某一区域的一致性。</p><p>第二步将场景建模为2.5D高斯混合模型(GMM)，计算关联并优化连续空间中的变换参数。描述某些轮廓附近的检索键允许快速检索有希望的候选对象。与最近在不同数据集上的许多工作相比，我们的方法是有竞争力的。本文报道的主要研究结果包括:</p><p>1.三维激光雷达BEV图像分层结构的新解释。</p><p>2.两步相似性检查，使用离散星座一致性验证和L2连续密度优化。</p><p>3.有效、实时的拓扑回环检测，具有精确的3-DoF度量位姿估计。</p><h6 id="二-、相关工作"><a href="#二-、相关工作" class="headerlink" title="二 、相关工作"></a>二 、相关工作</h6><p>A. 基于全局描述符的通用方法</p><p>通过提取三维关键点并利用关键点描述场景，可以解决三维点云的位置识别问题。在[7]中，3D中直接提取关键点，通过这些关键点投出的选票来确定循环候选点。PointNetVLAD[5]和LCDNet[14]采用基于dnn的点特征提取方法提取特征。</p><p>全局描述符可以在没有显式特征点的情况下生成。M2DP[15]使用不同平面的点分布作为全局描述符。眩光[16]将点对的相对方位角和距离映射为全局描述矩阵。OverlapTransformer[17]对OverlapNet[6]进行了推广，仅使用深度线索从距离图像创建全局描述符。虽然每个扫描使用一个全局描述符是常见的，但我们的方法从部分输入数据生成描述符，并且一个扫描可以有多个描述符。</p><p>B. 基于BEV的方法</p><p>许多方法采用极坐标BEV投影，假设重游时平移差较小。ScanContext[4]将三维点的径向和方位坐标映射为矩阵行和列，并使用环特征进行检索。DiSCO[11]将极BEV变换到频域，使描述子不变偏航。LiDAR Iris[12]在极BEV图像条带上使用LoG-Gabor滤波器来提高表示能力。</p><p>另一种类型的BEV投影使用二维笛卡尔坐标。ScanContext++[9]通过移位和顺序翻转增加了矩阵描述符。其他方法主要采用图像匹配管道，但难以提取稳定的图像特征。在[18]中研究了利用图像特征检测器和描述符匹配二维激光雷达占用网格的方法。SPI[13]在子映射BEV和SuperPoint和SuperGlue上使用NetVLAD全局描述符进行特征匹配。BVMatch[10]对BEV图像应用Log-Gabor滤波器后，使用FAST检测器提取特征。这些方法都侧重于在纯图像上寻找不变性，这很直观，但忽略了三维激光雷达点云的特点。</p><p>C. 基于对象和图的方法</p><p>近年来，基于对象和分割的方法逐渐受到人们的欢迎。SegMatch[1]从局部点云图中提取片段，并使用手工制作的分数描述它们。SegMap[8]，[19]用数据驱动的描述符改进了SegMatch，[20]中使用了一个高效的几何一致性验证。基于对象的方法与图密切相关。SGPR[21]对实例图使用语义分割，并使用图相似度网络进行匹配。GOSMatch[22]只使用3种语义类别，6种配对关系，使用基于直方图的顶点描述符和图描述符进行匹配。将[23]片段点云种子到对象中，并在对象投影之前将极BEV坐标放在一个主要对象上。BoxGraph[24]使用对象的包围盒作为图顶点，量化顶点和边的成对相似性，以找到最优的图匹配。</p><p>轨迹[25]编码片段的结构-外观特征及其跨帧的可重复性。段和对象是环境的紧凑表示，但它们依赖于段或语义检测器，由于现实世界中的领域缺口，这些检测器可能很脆弱。此外，基于图的方法通常需要两两相似度检查[21]，[24]，不清楚如何进行有效的检索。</p><h6 id="三、-bev上的轮廓线"><a href="#三、-bev上的轮廓线" class="headerlink" title="三、 bev上的轮廓线"></a>三、 bev上的轮廓线</h6><p>在这一节中，我们介绍轮廓抽象(CA)的概念。我们的投影步骤的灵感来自于ScanContext++[9]中的Cart Context，它使用笛卡尔坐标在2D中创建像图像像素一样的箱子，并记录每个箱子中点的最大高度(<strong>图1</strong>)。</p><p>![01](C:\Users\yudin\Pictures\Contour context\01.png)</p><p>​        图一:样本点云及其笛卡尔BEV。数据来自1648激光扫描，KITTI里程计序列08。</p><p>为了节省空间，我们请读者参考[9]的详细定义。为便于以后参考，像素p的符号为</p><p>![02](C:\Users\yudin\Pictures\Contour context\02.png)</p><p>其中pxy为像素在BEV坐标系中的2D坐标，pz为像素的高度(即像素值)。</p><p>在预先设定的高度对BEV图像进行切片，以获得垂直结构信息(<strong>图2a</strong>)。每一层的像素8-连接形成一个轮廓，因此被称为轮廓上下文。高度离散化为分层运算和对孤立轮廓的描述奠定了基础。</p><p>聚焦于统计量，我们用二维高斯分布(图2b)和一些描述性变量表示个体轮廓。这加剧了信息的丢失，但它使我们能够用<strong>统一的参数化方法对各种形状的轮廓进行编码</strong>。我们将原始轮廓定义为8个连通像素的集合，Al,s表示从BEV图像中切割出的第l级第s个原始轮廓。等高线抽象Cl,s的完全参数化是:</p><p>![04](C:\Users\yudin\Pictures\Contour context\04.png)</p><p>![05](C:\Users\yudin\Pictures\Contour context\05.png)</p><p>物理解译:na为像素数，hm为平均高度，xc为质心(CoM)，xm是高度加权的CoM， {vi， λi}是λ1≥λ2的特征向量特征值对形状协方差C。大CAs从BEV图像中总结了数十个像素，这使得它们在保持2D轮廓的平均位置(即xc)方面非常可靠。为了区分CAs在每个级别上的重要性，我们将它们按照na降序排序，然后用序列id <strong>s</strong>对它们进行索引。</p><p>![03](C:\Users\yudin\Pictures\Contour context\03.png)</p><p>图2 (a) BEV切片图像。(b)各级别的前十名。(c)(d)不同锚点的两个cac。纯色椭圆(黄色在(c)，绿色在(d))和黑色边缘是锚点，其他是外围的。(e) CAs用作2.5D GMM组件。</p><h6 id="四、-闭环检测器设计"><a href="#四、-闭环检测器设计" class="headerlink" title="四、 闭环检测器设计"></a>四、 闭环检测器设计</h6><p><strong>A.轮廓星座</strong></p><p>我们使用一种称为轮廓抽象星座(CAC)的类图结构来描述部分BEV。它由一个锚定CA和附近几个不同水平的外围CA组成(图2c, 2d)。我们使用三个顺序步骤来检查两个cac的相似性，这两个cac是检索中的候选者(章节IV-C，图3)。</p><p>**1)锚CA相似性:**进行相似性检查的两个CA应该来自同一个级别。如果所选参数对不一致，我们拒绝CA对。我们定义了一个具有标量二进制输出的相似性检查函数SC:</p><p>![06](C:\Users\yudin\Pictures\Contour context\06.png)</p><p>其中x1和x2是检查中的两个变量，tp和ta是百分比和绝对差异阈值。有五个标量通过测试(na, hm，||xc−xm||2，λ1和λ2)，每个标量使用自己的tp和ta集合。</p><p>**2)星座结构相似性:**这一步寻找一个具有尽可能多的外围CA CoM对一致性的相对变换。在满足锚CA对相似度的情况下，假设锚CA对的com点相同，则只剩下二维旋转。为了有效地解决这个问题，我们把它分成两个小问题:</p><p><strong>找到距离锚点大致相同的ca，然后找到大多数外围ca投票的旋转。</strong></p><p>在<strong>第一个小步骤</strong>中，我们使用一个<strong>二进制向量b</strong>来记录外围CAs的粗距离和级别，它是一个零向量，设为:</p><p>![07](C:\Users\yudin\Pictures\Contour context\07.png)</p><p>其中，φ(d, l)将外围锚距d和外围l映射为比特。它是在扫描预处理过程中计算的。利用两个二进制向量的逐位和，我们可以建立潜在的外围CA对，其与锚点的距离相似(AND的结果)。候选人名单为</p><p>![08](C:\Users\yudin\Pictures\Contour context\08.png)</p><p>其中，{1i C, 2i C}分别由来自第1阶和第2阶CAC的成对外围ca组成。</p><p>对于<strong>第二个小步骤</strong>，我们根据ψ(1 i C) - ψ(2 i C)对Ldist进行排序，其中ψ(j i C)计算CAC锚点处测得的外围CA的方位角。比较不同坐标系的方位角通常是没有意义的，因为它们是在局部坐标中测量的。然而，如果两个外围ca是真正匹配的，取两个方位角之间的差将显示两个局部坐标之间的相对旋转加上一些常量偏移。简而言之，<strong>对相同旋转进行投票的CA对有未知但接近的ψ(1 i C)−ψ(2 i C)。我们可以通过迭代带有某个角度窗口的排序Ldist，在一次传递中找到选票最多的角度集群。星座实际上是固定的，距离和旋转都被固定在CAC锚定框架中。</strong></p><p>3)星座两两相似度:使用(4)中相同的相似度检查函数，我们进一步检查上一步中配对的外围CAs。通过调整剩余CA对的对数阈值，我们可以将积极预测的数量限制到下一阶段。</p><p><strong>B. 基于GMM的分布建模</strong></p><p><strong>1)直觉和公式:</strong></p><p>Sec. IV-A.3可能不太准确(就是上面一段)，甚至是错误的，因为许多CA由于成对CA相似度的要求而浪费了。这通常是由离散化结果不一致引起的。例如在图4中，直观地看，左上方两个CA的组合应该与右上方同一级别的单个CA高度相似。为了量化这一想法，我们进一步将相似性检验建模为2.5D分布-分布(D2D)相关最大化问题。与那些具有确定性的对应相比，它扩大了吸引区域。我们首先定义3D扫描CAs构造的GMM:</p><p>![09](C:\Users\yudin\Pictures\Contour context\09.png)</p><p>其中L是感兴趣的水平集，<strong>δ(·)是Dirac delta函数</strong>，N(x | µ，Σ)是均值µ和协方差Σ在x处计算的高斯PDF（<strong>probability density function：概率密度</strong>）, Na &#x3D;ΣL∈LΣs nl,s a。</p><p>(7)中的定义是R3中的概率密度函数(即，在R3上的积分正好为1)。<strong>高斯分布概率密度函数的积分等于1</strong></p><p>图2e显示了混合组分(CA椭圆)的图示。信息水平较低的ca被排除在外。混合成分按其像素面积加权，这是随机像素归属于哪种混合的唯一提示。</p><p><strong>作为一种基于bev的方法，我们的变换估计只包括x, y和偏航角</strong>（只关注平面上的位置和方向）。此外，第三个维度级别与其他两个没有可比性（即无法直接进行数值比较。）。它与狄拉克delta相加，因此可以精确地定义连续空间中的分层运算和优化。因此，我们将这种方法称为基于2.5 d的方法。</p><p>（为了在连续空间中准确定义分层运算和优化，作者使用了狄拉克（Dirac）δ函数的概念。狄拉克δ函数是一个特殊的函数，在一个点上的值为无穷大，其余点上的值为零，并且在整个空间上的积分等于1。通过将狄拉克δ函数与第三个维度级别相加，作者能够精确地定义连续空间中的分层运算和优化。</p><p>基于以上思想和方法，作者将他们的方法称为基于2.5D的方法。这是因为他们在处理数据时只考虑了平面上的位置和方向（2D），但通过与狄拉克δ函数的相加操作，他们能够在连续空间中进行分层运算和优化，使其在某种程度上具有了第三个维度的效果（0.5D）。这种方法可以在不引入完整三维建模的情况下，更高效地处理和估计环境信息，适用于某些特定的应用场景。）</p><p>**2)优化:**为了度量两个gmm之间的相似性，我们采用L2距离，L2距离是更一般散度族的一种特殊情况，对于高斯分布[26]具有封闭的表达式。两个分布f和变换后的g之间L2距离的一般形式可以写成</p><p>![010](C:\Users\yudin\Pictures\Contour context\010.png)</p><p>其中T(·，θ)是参数θ的等距变换。由于T是等距的，积分区间是整个空间，所以 ∫g2（平方）dx &#x3D;∫T2（平方）(g， θ)dx。(9)右边的第一项和第三项可以在不知道θ的情况下计算。我们可以用式(9)中相同的变量项表示概率密度相关cor(·，·)为:</p><p>![011](C:\Users\yudin\Pictures\Contour context\011.png)</p><p>显然，最小化L2距离等同于最大化两个密度之间的相关性，而相关性是一种归一化度量。最后，我们可以制定变换参数及相关优化问题为:</p><p>![012](C:\Users\yudin\Pictures\Contour context\012.png)</p><p>其中，gmmC1(x)和gmmC2 (x)是(7)中定义的两个扫描的2.5D gmm, x是向量化变量，θ是仅限于x、y和偏航的变换参数。我们使用优化后的相关性作为最终的相似度得分。</p><p>注1:我们用Ceres[27]用解析导数求解式(11)中的一般无约束最小化问题。在3D NDT D2D配准中也有类似的最小化方法，即[28]不对分母求导，这实际上不能最小化目标函数。</p><p>注2:在实践中，为了在优化过程中提高效率，我们忽略了距离太远的CA对。这将导致当前相关值的永久低估。然而，这种交换是值得的，因为经过修剪的项的贡献是不显著的</p><p><strong>C.检索设计</strong></p><p>在实际应用中，在进行全尺度相似度计算[5]之前，最好基于一些紧凑描述符预先选择一小部分有希望的候选对象。为此，我们提出了一种基于给定轮廓及其在BEV图像上的邻近特征的低维和偏摆不变的检索键。</p><p>如第四章a节所述，类似的cac也有类似的锚定ca。因此，在检索密钥时应利用锚ca的量化特征。在描述CA(2)的变量中，我们使用细胞计数(na)和轴长信息(λ1， λ2)来创建区分键维:</p><p>![013](C:\Users\yudin\Pictures\Contour context\013.png)</p><p>其中s为CA在l层的序列id。前两项一般描述CA椭圆的形状。最后一项包括该层中所有以前的细胞计数的总和，这表明当前CA在其层中的相对重要性，并可以在一个截然不同的邻居中惩罚类似的CA。</p><p>其余关键尺寸编码以CA的xc为中心的BEV图像上的圆形感兴趣区域(RoI)。为了获得偏航不变性，像素到xc的距离是我们使用的唯一位置信息。与[4]不同，我们不从占用率创建环键。相反，我们在RoI中使用欧几里德空间中的所有像素。这是因为归一化淡化了遥远地方的BEV像素的重要性。</p><p>因为更多的像素被挤进一个距离环中。每个距离级像素的绝对数量有更大的范围，可以更好的区分不同的地方。当将感兴趣区域的像素分选为距离段时，离散化误差会引起显著的扰动。与[16]类似，我们将每个像素的距离建模为一维高斯分布，然后对距离段进行数值积分，得到平滑的描述值(图5)。段i的值定义为满足的Kl,s roi(i)</p><p>![014](C:\Users\yudin\Pictures\Contour context\014.png)</p><p>式中di为除距离时的第i个阈值，Lev(h)返回高度h所属的轮廓水平，lb为允许一个像素在其之上贡献密钥的基准水平，σd为有效BEV像素的分布宽度参数，R为RoI半径。区段值的物理意义是高于基本区段的层数对投影在该距离区段中的像素的总和。给定Cl,s的完整检索键是向量</p><p>![015](C:\Users\yudin\Pictures\Contour context\015.png)</p><p>其中n为RoI中距离段的个数，w1为权重参数，因为检索关键字的两部分具有不同的物理意义。检索键仅为选定层中的顶级ca创建。查询键只搜索该级别的KD-tree。由于低维键，我们的实验(V-B.3节)使用nanoflann[29]保证了实时。</p><h6 id="五、实验及结果"><a href="#五、实验及结果" class="headerlink" title="五、实验及结果"></a>五、实验及结果</h6><p>A.评价标准的定义</p><p>我们简要概括了三种主流协议，它们定义了ground truth (GT) loop状态，并在给出预测时判断真假:</p><p>1)检查任何分配对的相似性。如果空间距离小于l1，则真环状态为真;如果距离大于l2 (l1 &lt; l2)，则true为false。预测结果由一个变化的相似度阈值控制。由[21]，[30]，[31]使用。</p><p>2)仅使用GT环评估姿态。从所有有效的过去姿势中检索top-N候选人。如果有真邻居，则检索为真阳性(TP)，否则为假阴性(FN)[5]，[11]。</p><p><strong>3)从所有有效的过去姿势中找出最相似的候选人。当相似度高于阈值时，如果与候选对象的空间距离小于l3，则报告TP，否则报假阳性(FP)。当相似度低于阈值，但在l3内存在有效的过去姿势时，报告fn[14]。</strong></p><p>我们的选择是3)，原因有两方面。</p><p>首先，我们的目标是全局定位，因此应该评估在所有有效的历史扫描中寻找循环的能力。</p><p>其次，协议直接要求最好的候选方案，从而减少后续处理的工作量。相比之下，协议1)报告了分配的提议对之间的相似性，这不必要地过多地强调了次优候选。方案2)不能评估拒绝错误环路(即精度)的能力，因为它们只测试GT环路，因此不能记录FP。在计算过程中，我们设置l3 &#x3D; 5m，并从循环候选帧中排除当前帧之前的150帧。</p><p>B、公共数据集的评估</p><p>我们在KITTI数据集[32]上进行评估。由于GT姿势问题[14]，我们使用SemanticKITTI[33]中的GT姿势。为了证明该方法的鲁棒性和通用性，我们还在MulRan数据集[34]上进行了测试。与KITTI试验相比，我们只使用了两个不同的参数:BEV切片高度、平均高度差阈值。修改是由于MulRan的激光雷达有22.5◦垂直视场高于水平平面(2◦在KITTI)。使用中的参数可以在我们的代码库中找到。</p><p>我们测试了KITTI 00、02、05和08(表中的K0x)，其中循环丰富，MulRan KAIST01和riverde02(表中的MK01和MR02)。我们选择了六种基线方法进行比较:M2DP[15]、SC[4]、IRIS[12]、SGPR[21]、OT[17]和LCDNet[14]，最后三种方法是基于学习的(使用其公共代码库中的预训练模型进行评估)。MulRan数据集没有语义标签，因此我们不对其运行SGPR。为了展示泛化能力，LCDNet和OT在各自的论文[14]，[17]中直接使用了经过预处理的模型用于真实世界的测试&#x2F;其他数据集。所以我们也要对穆兰做同样的事。但我们注意到，如果重新训练，他们的表现可能会更好。</p><ol><li>Precision and Recall:使用Precision Recall curve (PR-curve)和max F1 score对拓扑环路检测进行评价是一个约定[4]，[6]，[16]，[35]。F1的“平均”精确度和召回率。我们在图6中报告了PR-curve，在Tab中报告了F1的最大得分。一、根据结果，IRIS是最好的手工基线法，但缺乏检索实际使用。LCDNet在KITTI上有出色的性能。值得注意的是，与LCDNet[14]相比，OT[17]对MulRan数据集的泛化效果相当好，而两者都使用了预先训练的模型。我们的PR-curve在MR02上的表现不太好，因为它主要包含树木和河岸上的开阔区域，当建模为分布时，信息丢失是严重的。然而，我们的F1最高得分是最高的。</li></ol><p>​![016](C:\Users\yudin\Pictures\Contour context\016.png)表一:F1最高得分结果。</p><p>​* SK:使用SemanticKITTI语义标签。+最好的分数是鼓励和第二最好的划线。</p><p>2)度量姿态估计:见表。ii。</p><p>​                                               表二:在最大F1得分时，TP循环的三个自由度MPE。</p><p>![018](C:\Users\yudin\Pictures\Contour context\018.png)</p><p>3)计算复杂度:不同方法的资源消耗是依赖于实现的，不能直接比较。所以我们只在Tab中列出我们的时间消耗数据。三供参考。原型是用c++编写的，并在带有16GB RAM的英特尔酷睿<a href="mailto:&#x69;&#x37;&#x2d;&#x39;&#x37;&#53;&#48;&#x48;&#x40;&#x32;&#x2e;&#54;&#x30;&#x47;&#72;&#x7a;">&#x69;&#x37;&#x2d;&#x39;&#x37;&#53;&#48;&#x48;&#x40;&#x32;&#x2e;&#54;&#x30;&#x47;&#72;&#x7a;</a>笔记本电脑CPU上进行评估。我们自己编写的代码中不使用多线程。我们将每个序列运行3次，然后取平均值。关于影响复杂度的细节，我们在3个级别索引检索键，每个级别有6个锚ca。外围ca为4级中每级前10名。每个10-D键在每个查询中检索50个候选项。kd -tree每100次扫描更新一次，每次更新一个级别。我们把总体效率归因于基本操作的简单性。</p><p>![017](C:\Users\yudin\Pictures\Contour context\017.png)</p><p>​                                                       图6:本方法的查全率曲线及6条基线。</p><p>表III:数据集大小和分解的平均时间成本每扫描(ms)。</p><p>![019](C:\Users\yudin\Pictures\Contour context\019.png)</p><p>C.讨论</p><p>1)重新考虑评估标准:在实际部署中，无法通过单一扫描来区分TP和FP。所有积极的预测将经过相同的后处理(例如，共识检查，ICP)。因此，一个有趣的问题是:FP循环闭包真的那么有害吗?为了回答这个问题，我们研究了在协议中被识别为FP的环闭包事件中的MPE错误，结果如图7所示。我们发现许多FPs具有与TP相比的度量误差，这可以作为ICP[14]的一个很好的初始猜测。这意味着，如果我们有一些机制(例如，相对构成共识)来消除极端异常值，它们，尽管FP被定义为，实际上可以使下游任务受益。因此，我们认为需要能够充分反映环路检测器性能的评价标准。</p><p>![020](C:\Users\yudin\Pictures\Contour context\020.png)</p><p>图7:最大F1得分时FP预测的度量误差分布。在所有6个序列中，192个FP预测中有52个(27%)的平移和旋转误差分别小于1.0m和1.0◦(左下角的黑色矩形)。</p><p>六、结论</p><p>本文提出了一种三维激光雷达在城市自动驾驶场景下的闭环检测方法。该方法在拓扑环检测性能方面具有较高的实时检测精度和查全率，且无需基于icp的6自由度精细优化，3自由度米制位姿估计结果也具有较高的准确性。虽然BEV表示是一种有效的简化方法，但高程方向的信息损失是不可避免的。na¨ıve轮廓分割对于大而自然的结构也存在困难。我们可以通过充分利用点云的三维空间和更复杂的分割技术来提高性能。</p><p>1.等值线上下文如何解释从 3D LiDAR 点投影的笛卡尔鸟瞰图 （BEV） 图像？</p><p>Contour Context 将从 3D LiDAR 点投影的笛卡尔俯视图（BEV）图像解释为结构的分层分布。它通过在不同高度处切片 BEV 并在每个级别上连接像素来恢复 BEV 的高程信息，形成轮廓。每个轮廓由抽象信息参数化，例如像素计数、中心位置、协方差和平均高度。</p><p>2.在等值线上下文中计算两个BEV的相似性涉及哪些两个步骤？</p><p>Contour Context 计算两个 BEV 的相似度分为两个步骤：离散步骤和连续步骤。第一步检查局部多个轮廓形成的类似图形的共识。第二步将场景建模为 2.5D 高斯混合模型（GMM），以计算相关性并优化连续空间中的变换参数。通过表征一些轮廓的邻域的检索键，可以快速检索有前途的候选项。</p><p>3.等值线上下文如何优化连续空间中的相对变换？</p><p>Contour Context 通过将场景建模为 2.5D 高斯混合模型（GMM）来优化连续空间中的相对变换。该模型将大多数轮廓建模为高斯混合模型，用于计算相关性并优化相对变换。同时，设计了一个检索键来加速由分层 KD 树索引的数据库的搜索。</p><p>4.文中的CA是什么</p><p>CA 是 Contour Context 中的缩写，指的是 Contour Abstraction，即轮廓抽象。在 Contour Context 中，CA 是指将从 3D LiDAR 点投影的笛卡尔俯视图（BEV）图像解释为结构的分层分布，并通过在不同高度处切片 BEV 并在每个级别上连接像素来恢复 BEV 的高程信息，形成的轮廓。每个轮廓由抽象信息参数化，例如像素计数、中心位置、协方差和平均高度。</p><p>5.文中的CAC是什么</p><p>CAC 是 Contour Context 中的缩写，指的是 Contour Anchor Cluster，即轮廓锚点聚类。在 Contour Context 中，CAC 是指将相似的轮廓锚点聚类在一起，形成的一组轮廓。每个 CAC 由一个锚点和一组周边轮廓组成，锚点是 CAC 中最大的轮廓，周边轮廓是与锚点相邻的轮廓。</p><p>6.成对CA相似度的要求（第三页）</p><p>对于成对 CA 相似度的要求，在 Contour Context 中，我们<strong>使用相似性检查函数来检查每个 CAC 中的周边轮廓与锚点轮廓之间的相似度。我们使用每个轮廓的形状协方差矩阵的特征向量和特征值来计算相似度。如果两个轮廓之间的相似度高于阈值，则将它们视为相似的轮廓，并将它们分配到同一个 CAC 中。</strong>这个过程可以在第二个阶段中进一步优化，通过将场景建模为 2.5D 高斯混合模型（GMM）来优化连续空间中的相对变换。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h5 id=&quot;Contour-Context-Abstract-Structural-Distribution-for-3D-LiDAR-Loop-Detection-and-Metric-Pose-Estimation-论文阅读-ICRA’23&quot;&gt;&lt;a href=&quot;#Cont</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://github.com/ydy321/ydy321.git/2023/10/18/hello-world/"/>
    <id>https://github.com/ydy321/ydy321.git/2023/10/18/hello-world/</id>
    <published>2023-10-18T11:08:17.304Z</published>
    <updated>2023-10-18T11:05:44.333Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
